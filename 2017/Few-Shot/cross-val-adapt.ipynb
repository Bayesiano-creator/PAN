{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffd56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7c20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "\n",
    "_LANGUAGE_         = 'es'\n",
    "_PRETRAINED_LM_    = 'pysentimiento/robertuito-base-cased'\n",
    "_PREPROCESS_TEXT_  = True\n",
    "_TWEET_BATCH_SIZE_ = 5\n",
    "_ADAPTER_CONFIG_   = transformers.ParallelConfig(mh_adapter = True, reduction_factor = 32)\n",
    "_MAX_SEQ_LEN_      = 128\n",
    "_OUTPUT_DIR_       = 'adapter_checkPoints'\n",
    "_LOGGING_STEPS_    = 2\n",
    "_NUM_AUTHORS_      = [8, 16, 32, 64, 128, 256, 512]\n",
    "_K_FOLD_CV_        = 5\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "_NO_GPUS_          = 2\n",
    "_BATCH_SIZE_       = int(32 / _NO_GPUS_)\n",
    "_EPOCHS_           = {'gender': 20, 'variety': 20}\n",
    "_LEARNING_RATE_    = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24462750",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13393cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL DICTONARIES -----------------------------------------------------------------------\n",
    "\n",
    "gender_dict    = {'female': 0, \n",
    "                  'male':   1}\n",
    "\n",
    "varietyEN_dict = {'australia'    : 0,\n",
    "                  'canada'       : 1,\n",
    "                  'great britain' : 2,\n",
    "                  'ireland'      : 3,\n",
    "                  'new zealand'   : 4,\n",
    "                  'united states': 5}\n",
    "\n",
    "varietyES_dict = {'argentina': 0,\n",
    "                  'chile'    : 1,\n",
    "                  'colombia' : 2,\n",
    "                  'mexico'   : 3,\n",
    "                  'peru'     : 4,\n",
    "                  'spain'    : 5,\n",
    "                  'venezuela': 6}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a6fa34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET LANGUAGE DIRECTORY\n",
    "\n",
    "if _LANGUAGE_ == 'en':\n",
    "    variety_dict = varietyEN_dict\n",
    "\n",
    "elif _LANGUAGE_ == 'es':\n",
    "    variety_dict = varietyES_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ede52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET LANGUAGE TOKENIZER\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(_PRETRAINED_LM_)\n",
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509445d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d36aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetPAN17 import BasePAN17, DatasetPAN17, DatasetCrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef668d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 84000\n",
      "\n",
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 56000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseTrain  = BasePAN17(Dir             = '../data',\n",
    "                      split            = 'train',\n",
    "                      language         = _LANGUAGE_,\n",
    "                      tokenizer        = tokenizer,\n",
    "                      gender_dict      = gender_dict,\n",
    "                      variety_dict     = variety_dict,\n",
    "                      tweet_batch_size = _TWEET_BATCH_SIZE_,\n",
    "                      max_seq_len      = _MAX_SEQ_LEN_,\n",
    "                      preprocess_text  = _PREPROCESS_TEXT_)\n",
    "\n",
    "baseTest  = BasePAN17(Dir             = '../data',\n",
    "                      split            = 'test',\n",
    "                      language         = _LANGUAGE_,\n",
    "                      tokenizer        = tokenizer,\n",
    "                      gender_dict      = gender_dict,\n",
    "                      variety_dict     = variety_dict,\n",
    "                      tweet_batch_size = _TWEET_BATCH_SIZE_,\n",
    "                      max_seq_len      = _MAX_SEQ_LEN_,\n",
    "                      preprocess_text  = _PREPROCESS_TEXT_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143f62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = DatasetPAN17(Base_Dataset = baseTest, label = 'gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba9d21",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e07a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e520320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 8 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/200 06:25 < 06:33, 0.25 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640600</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.596071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521300</td>\n",
       "      <td>0.663332</td>\n",
       "      <td>0.603274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.689176</td>\n",
       "      <td>0.603333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.711153</td>\n",
       "      <td>0.610952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.754629</td>\n",
       "      <td>0.611726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.817822</td>\n",
       "      <td>0.613512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.832711</td>\n",
       "      <td>0.613810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.882409</td>\n",
       "      <td>0.614940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.955413</td>\n",
       "      <td>0.611667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.991520</td>\n",
       "      <td>0.613988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-10\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-30] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-30\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-50] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-50\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-10] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-70\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-30] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-90\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-50] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-80 (score: 0.6149404761904762).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-80/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-80 (score: 0.6149404761904762).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6503571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 148.38it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/200 07:09 < 05:57, 0.25 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.633900</td>\n",
       "      <td>0.674462</td>\n",
       "      <td>0.572619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.674062</td>\n",
       "      <td>0.580238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.421500</td>\n",
       "      <td>0.686199</td>\n",
       "      <td>0.589167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.693935</td>\n",
       "      <td>0.592083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.760352</td>\n",
       "      <td>0.594583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.747430</td>\n",
       "      <td>0.601905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.790065</td>\n",
       "      <td>0.599940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.806497</td>\n",
       "      <td>0.603274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.869313</td>\n",
       "      <td>0.605774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.881684</td>\n",
       "      <td>0.597917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.942796</td>\n",
       "      <td>0.603810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-10\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-70] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-30\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-90] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-50\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-10] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-70\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-30] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-90\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-50] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-110\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-110/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-110/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-110/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-110/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-110/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-110/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-90 (score: 0.6057738095238095).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-90/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-90 (score: 0.6057738095238095).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-90/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-90/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6489285714285714: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 146.52it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 50/200 03:14 < 10:06, 0.25 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.663832</td>\n",
       "      <td>0.607619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.653829</td>\n",
       "      <td>0.608571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.660064</td>\n",
       "      <td>0.619107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.660195</td>\n",
       "      <td>0.616607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.712125</td>\n",
       "      <td>0.616131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-10\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-70] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-30\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-90] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-50\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-110] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-30 (score: 0.6191071428571429).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-30/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-30 (score: 0.6191071428571429).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-30/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-30/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6178571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 145.61it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/200 08:18 < 04:32, 0.26 it/s, Epoch 13/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.685366</td>\n",
       "      <td>0.553750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.563500</td>\n",
       "      <td>0.678359</td>\n",
       "      <td>0.568274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.685287</td>\n",
       "      <td>0.580179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.430800</td>\n",
       "      <td>0.690075</td>\n",
       "      <td>0.577560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>0.721792</td>\n",
       "      <td>0.588274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.724355</td>\n",
       "      <td>0.593155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>0.596429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.760139</td>\n",
       "      <td>0.600774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.795623</td>\n",
       "      <td>0.601190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.825023</td>\n",
       "      <td>0.597321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.857460</td>\n",
       "      <td>0.603988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.880104</td>\n",
       "      <td>0.602560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.924095</td>\n",
       "      <td>0.598095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-10\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-30\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-50\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-10] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-70\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-30] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-90\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-90/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-90/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-50] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-110\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-110/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-110/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-110/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-110/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-110/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-110/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-70] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-130\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-130/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-130/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-130/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-130/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-130/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-130/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-110 (score: 0.6039880952380953).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-110/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-110 (score: 0.6039880952380953).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-110/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-110/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-110/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-110/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6235714285714286: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 142.14it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 80/200 05:08 < 07:54, 0.25 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.682060</td>\n",
       "      <td>0.567024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>0.677813</td>\n",
       "      <td>0.583036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.456600</td>\n",
       "      <td>0.690869</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.693872</td>\n",
       "      <td>0.591190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.755381</td>\n",
       "      <td>0.586607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.599345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.786023</td>\n",
       "      <td>0.591726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.811718</td>\n",
       "      <td>0.591845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-10\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-10/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-10/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-90] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-30\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-30/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-30/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-110] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-50\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-50/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-50/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-130] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-10] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-70\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-70/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-70/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-30] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-60 (score: 0.5993452380952381).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-60/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-60 (score: 0.5993452380952381).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6457142857142857: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 141.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 8 authors per label:  {'accuracy': [0.6372857142857142, 0.013733245822322057], 'f1-score': [0.6003591459285674, 0.0337803528007935]}\n",
      "Working with 16 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/3f85c0ee804baf604258892a88dd52cdf051d2418a511dcab7cab99a85a3a1b3.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/795f97c54d814fec7e7c661c939f5f797bd6fb98c93716c51ca7f06335899b9f.27f4ebde81f46ec68cbdd9518932c83dd3d3eac62e312dedfb680d87341e94e9\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 640\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/400 05:17 < 08:01, 0.50 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.668453</td>\n",
       "      <td>0.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>0.654886</td>\n",
       "      <td>0.615060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.680819</td>\n",
       "      <td>0.618155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.707670</td>\n",
       "      <td>0.623810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.620893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.772763</td>\n",
       "      <td>0.631071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>0.814285</td>\n",
       "      <td>0.628155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>0.826493</td>\n",
       "      <td>0.630179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-50] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-70] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-140\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-120 (score: 0.6310714285714286).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-120/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-120 (score: 0.6310714285714286).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6803571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 143.60it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 640\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/400 06:34 < 06:38, 0.50 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686700</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>0.517440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.768489</td>\n",
       "      <td>0.528869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.889431</td>\n",
       "      <td>0.527738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.887227</td>\n",
       "      <td>0.542143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>0.889790</td>\n",
       "      <td>0.569107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.905229</td>\n",
       "      <td>0.574405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.573452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>1.004137</td>\n",
       "      <td>0.583036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>1.157622</td>\n",
       "      <td>0.571250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.210590</td>\n",
       "      <td>0.575060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-140] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-140\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-180\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.5830357142857143).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.5830357142857143).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6003571428571428: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 146.72it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 640\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/400 04:38 < 08:45, 0.50 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.686729</td>\n",
       "      <td>0.562619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.731708</td>\n",
       "      <td>0.563155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.869235</td>\n",
       "      <td>0.557440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.844113</td>\n",
       "      <td>0.571488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.865107</td>\n",
       "      <td>0.593988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.914313</td>\n",
       "      <td>0.593214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>0.954290</td>\n",
       "      <td>0.592679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-140] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-180] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-200] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-140\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-100 (score: 0.5939880952380953).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-100/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-100 (score: 0.5939880952380953).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6142857142857143: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 145.86it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 640\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/400 06:34 < 06:38, 0.50 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.664100</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.525893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.759546</td>\n",
       "      <td>0.539643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.881733</td>\n",
       "      <td>0.539762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.854416</td>\n",
       "      <td>0.562024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.922628</td>\n",
       "      <td>0.568393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.969613</td>\n",
       "      <td>0.575536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.996230</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>1.057096</td>\n",
       "      <td>0.588988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>1.157745</td>\n",
       "      <td>0.581845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>1.262715</td>\n",
       "      <td>0.578214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-140] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-140\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-180\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.5889880952380953).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.5889880952380953).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6096428571428572: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:19<00:00, 146.21it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 640\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/400 06:35 < 06:39, 0.50 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.705844</td>\n",
       "      <td>0.547738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.767924</td>\n",
       "      <td>0.550952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.923179</td>\n",
       "      <td>0.549821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.905528</td>\n",
       "      <td>0.560833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.920252</td>\n",
       "      <td>0.576905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.975646</td>\n",
       "      <td>0.575179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>1.031716</td>\n",
       "      <td>0.580060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1.120932</td>\n",
       "      <td>0.582738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>1.242012</td>\n",
       "      <td>0.575179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>1.351899</td>\n",
       "      <td>0.567679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-20\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-20/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-20/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-140] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-60\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-60/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-60/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-180] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-100\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-100/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-100/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-200] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-20] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-140\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-140/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-140/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-60] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-180\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-180/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-180/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-100] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.5827380952380953).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.5827380952380953).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6146428571428572: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 147.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 16 authors per label:  {'accuracy': [0.6238571428571429, 0.028716062489449346], 'f1-score': [0.6037027685368634, 0.01927943549239881]}\n",
      "Working with 32 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/3f85c0ee804baf604258892a88dd52cdf051d2418a511dcab7cab99a85a3a1b3.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/795f97c54d814fec7e7c661c939f5f797bd6fb98c93716c51ca7f06335899b9f.27f4ebde81f46ec68cbdd9518932c83dd3d3eac62e312dedfb680d87341e94e9\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/800 04:12 < 09:54, 0.94 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.643600</td>\n",
       "      <td>0.656015</td>\n",
       "      <td>0.622560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>0.688485</td>\n",
       "      <td>0.622679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.809604</td>\n",
       "      <td>0.598274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.753407</td>\n",
       "      <td>0.628631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.622619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.626786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-140] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-180] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-200] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.6286309523809523).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.6286309523809523).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6807142857142857: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 151.87it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/800 04:14 < 09:59, 0.93 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.648498</td>\n",
       "      <td>0.618810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.659760</td>\n",
       "      <td>0.630714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.710929</td>\n",
       "      <td>0.631786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.757144</td>\n",
       "      <td>0.637262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.882933</td>\n",
       "      <td>0.622024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.616845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.6372619047619048).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.6372619047619048).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6953571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 152.22it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/800 04:15 < 10:00, 0.93 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.631183</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.638660</td>\n",
       "      <td>0.650179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.685631</td>\n",
       "      <td>0.651488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.724028</td>\n",
       "      <td>0.655893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.843491</td>\n",
       "      <td>0.638452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.632262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-200] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.6558928571428572).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.6558928571428572).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6953571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 151.13it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/800 04:14 < 09:59, 0.93 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.635521</td>\n",
       "      <td>0.629167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.641200</td>\n",
       "      <td>0.638095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.633393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.740632</td>\n",
       "      <td>0.640298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.868288</td>\n",
       "      <td>0.626190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.904113</td>\n",
       "      <td>0.620893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.6402976190476191).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.6402976190476191).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6953571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 148.69it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/800 04:15 < 10:01, 0.93 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.650391</td>\n",
       "      <td>0.616131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.659485</td>\n",
       "      <td>0.635357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.713329</td>\n",
       "      <td>0.626369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.745567</td>\n",
       "      <td>0.636012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.875656</td>\n",
       "      <td>0.616310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.920343</td>\n",
       "      <td>0.602738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-40\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-40/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-40/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-200/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-200] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-160 (score: 0.6360119047619047).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-160/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-160 (score: 0.6360119047619047).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.6953571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 152.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 32 authors per label:  {'accuracy': [0.6924285714285715, 0.0058571428571428715], 'f1-score': [0.6727261174083762, 0.0031541034803075347]}\n",
      "Working with 64 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/3f85c0ee804baf604258892a88dd52cdf051d2418a511dcab7cab99a85a3a1b3.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/795f97c54d814fec7e7c661c939f5f797bd6fb98c93716c51ca7f06335899b9f.27f4ebde81f46ec68cbdd9518932c83dd3d3eac62e312dedfb680d87341e94e9\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2560\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1600\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='560' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 560/1600 05:37 < 10:29, 1.65 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.633772</td>\n",
       "      <td>0.643750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.660513</td>\n",
       "      <td>0.643690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.711895</td>\n",
       "      <td>0.645952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.753205</td>\n",
       "      <td>0.638690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.805760</td>\n",
       "      <td>0.650298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>0.849004</td>\n",
       "      <td>0.645714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.970246</td>\n",
       "      <td>0.623393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-40] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-400\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-560\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-560/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-560/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-560/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-560/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-400 (score: 0.6502976190476191).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-400/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-400 (score: 0.6502976190476191).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7042857142857143: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 150.04it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2560\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1600\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 480/1600 04:45 < 11:09, 1.67 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.653884</td>\n",
       "      <td>0.625595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.690236</td>\n",
       "      <td>0.631131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.766593</td>\n",
       "      <td>0.634048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.782496</td>\n",
       "      <td>0.639940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.842459</td>\n",
       "      <td>0.639107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.911682</td>\n",
       "      <td>0.622738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-400] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-400\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-560] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-320 (score: 0.6399404761904762).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-320/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-320 (score: 0.6399404761904762).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.705: 100%|██████████████████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 150.47it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2560\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1600\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 480/1600 04:50 < 11:20, 1.65 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.643814</td>\n",
       "      <td>0.645179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.658794</td>\n",
       "      <td>0.656369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.716154</td>\n",
       "      <td>0.656548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.767870</td>\n",
       "      <td>0.659167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.785158</td>\n",
       "      <td>0.658274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.853260</td>\n",
       "      <td>0.649107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-400] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-400\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-320 (score: 0.6591666666666667).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-320/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-320 (score: 0.6591666666666667).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7057142857142857: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 153.84it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2560\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1600\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='560' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 560/1600 05:31 < 10:18, 1.68 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.647272</td>\n",
       "      <td>0.638036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.670129</td>\n",
       "      <td>0.645298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.729020</td>\n",
       "      <td>0.644940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.784515</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.802038</td>\n",
       "      <td>0.649048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.869877</td>\n",
       "      <td>0.637024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.958899</td>\n",
       "      <td>0.638631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-400] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-400\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-560\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-560/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-560/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-560/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-560/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-400 (score: 0.6490476190476191).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-400/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-400 (score: 0.6490476190476191).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7189285714285715: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 161.62it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2560\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1600\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 480/1600 04:44 < 11:06, 1.68 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.653136</td>\n",
       "      <td>0.628036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.676962</td>\n",
       "      <td>0.636369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.742496</td>\n",
       "      <td>0.638750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.763128</td>\n",
       "      <td>0.642619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.824391</td>\n",
       "      <td>0.639405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.878150</td>\n",
       "      <td>0.631964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-80\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-80/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-80/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-400] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-400\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-400/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-400/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-560] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-80] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-320 (score: 0.6426190476190476).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-320/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-320 (score: 0.6426190476190476).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.705: 100%|██████████████████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 162.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 64 authors per label:  {'accuracy': [0.7077857142857144, 0.005589713584718266], 'f1-score': [0.687684720440162, 0.019845425319650088]}\n",
      "Working with 128 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/3f85c0ee804baf604258892a88dd52cdf051d2418a511dcab7cab99a85a3a1b3.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/795f97c54d814fec7e7c661c939f5f797bd6fb98c93716c51ca7f06335899b9f.27f4ebde81f46ec68cbdd9518932c83dd3d3eac62e312dedfb680d87341e94e9\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5120\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1120' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1120/3200 06:56 < 12:55, 2.68 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.610500</td>\n",
       "      <td>0.612351</td>\n",
       "      <td>0.667440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>0.625783</td>\n",
       "      <td>0.667679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494200</td>\n",
       "      <td>0.639760</td>\n",
       "      <td>0.672083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.702366</td>\n",
       "      <td>0.662143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.672857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>0.666488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.777387</td>\n",
       "      <td>0.672738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-800\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-800 (score: 0.6728571428571428).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-800/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-800 (score: 0.6728571428571428).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-800/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-800/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading module weights from adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7342857142857143: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:18<00:00, 155.30it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5120\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 640/3200 03:58 < 15:57, 2.67 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>0.627813</td>\n",
       "      <td>0.656607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.657811</td>\n",
       "      <td>0.658810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.687314</td>\n",
       "      <td>0.652917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443100</td>\n",
       "      <td>0.761017</td>\n",
       "      <td>0.651845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-800] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-320 (score: 0.6588095238095238).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-320/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-320 (score: 0.6588095238095238).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7278571428571429: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 159.37it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5120\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 960/3200 05:52 < 13:44, 2.72 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>0.613008</td>\n",
       "      <td>0.672262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.651596</td>\n",
       "      <td>0.669226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.462300</td>\n",
       "      <td>0.660715</td>\n",
       "      <td>0.676548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.692017</td>\n",
       "      <td>0.680536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.713926</td>\n",
       "      <td>0.680357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>0.745108</td>\n",
       "      <td>0.667024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-800\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-640 (score: 0.6805357142857142).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-640/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-640 (score: 0.6805357142857142).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7367857142857143: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 157.79it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5120\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1120' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1120/3200 06:52 < 12:47, 2.71 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.600800</td>\n",
       "      <td>0.623244</td>\n",
       "      <td>0.656548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>0.662946</td>\n",
       "      <td>0.657024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.467600</td>\n",
       "      <td>0.685898</td>\n",
       "      <td>0.657262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.729940</td>\n",
       "      <td>0.660238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.737684</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.792788</td>\n",
       "      <td>0.653869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>0.819218</td>\n",
       "      <td>0.655952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-800] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-800\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1120\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1120/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1120/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1120/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1120/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1120/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-800 (score: 0.6625).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-800/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-800 (score: 0.6625).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-800/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-800/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7457142857142857: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 163.80it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5120\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 960/3200 05:52 < 13:45, 2.71 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>0.631938</td>\n",
       "      <td>0.653274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.663051</td>\n",
       "      <td>0.652321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.683847</td>\n",
       "      <td>0.656190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443100</td>\n",
       "      <td>0.725859</td>\n",
       "      <td>0.666607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.730270</td>\n",
       "      <td>0.657560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>0.798485</td>\n",
       "      <td>0.645119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-160\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-160/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-160/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-480\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-480/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-480/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-800] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-800\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-800/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-800/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1120] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-160] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-640 (score: 0.6666071428571428).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-640/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-640 (score: 0.6666071428571428).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7246428571428571: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 163.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 128 authors per label:  {'accuracy': [0.7338571428571429, 0.00735193990781773], 'f1-score': [0.7279624959710755, 0.013607124990922394]}\n",
      "Working with 256 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/3f85c0ee804baf604258892a88dd52cdf051d2418a511dcab7cab99a85a3a1b3.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/795f97c54d814fec7e7c661c939f5f797bd6fb98c93716c51ca7f06335899b9f.27f4ebde81f46ec68cbdd9518932c83dd3d3eac62e312dedfb680d87341e94e9\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='6400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/6400 08:04 < 18:51, 3.96 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>0.619614</td>\n",
       "      <td>0.669226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.535800</td>\n",
       "      <td>0.588963</td>\n",
       "      <td>0.690119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.490900</td>\n",
       "      <td>0.594969</td>\n",
       "      <td>0.693452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.615044</td>\n",
       "      <td>0.700476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.419500</td>\n",
       "      <td>0.651101</td>\n",
       "      <td>0.695119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>0.669984</td>\n",
       "      <td>0.694821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1600\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-480] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7004761904761905).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7004761904761905).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7775: 100%|█████████████████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 157.19it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2240' max='6400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2240/6400 09:28 < 17:36, 3.94 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>0.641373</td>\n",
       "      <td>0.654405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.641472</td>\n",
       "      <td>0.673095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>0.638489</td>\n",
       "      <td>0.680655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.671631</td>\n",
       "      <td>0.684107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.701336</td>\n",
       "      <td>0.685238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>0.680952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.806297</td>\n",
       "      <td>0.684643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-800] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1280] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1600] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1600\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1920] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-2240\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2240/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2240/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2240/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2240/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2240/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1600 (score: 0.6852380952380952).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1600/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1600 (score: 0.6852380952380952).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1600/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_adapter.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7657142857142857: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 159.96it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='6400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/6400 08:03 < 18:49, 3.97 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.628593</td>\n",
       "      <td>0.671012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.612540</td>\n",
       "      <td>0.693988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.621833</td>\n",
       "      <td>0.697679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.643274</td>\n",
       "      <td>0.706071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.691732</td>\n",
       "      <td>0.700536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.697360</td>\n",
       "      <td>0.699345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1280] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1600] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1920] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1600\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-2240] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7060714285714286).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7060714285714286).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7814285714285715: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 159.13it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='6400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/6400 08:04 < 18:52, 3.96 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>0.616551</td>\n",
       "      <td>0.677202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.601875</td>\n",
       "      <td>0.700774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>0.590751</td>\n",
       "      <td>0.707798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.613631</td>\n",
       "      <td>0.712321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.659262</td>\n",
       "      <td>0.699702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.681239</td>\n",
       "      <td>0.697143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1280] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1600] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1600\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1920] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7123214285714285).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7123214285714285).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7778571428571428: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 164.33it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6400\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='6400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/6400 08:05 < 18:53, 3.95 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>0.643271</td>\n",
       "      <td>0.646607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.636650</td>\n",
       "      <td>0.677976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>0.629276</td>\n",
       "      <td>0.681845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.653643</td>\n",
       "      <td>0.693988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.685845</td>\n",
       "      <td>0.683036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.724062</td>\n",
       "      <td>0.681548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-320\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-320/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-320/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-960\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-960/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-960/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1280] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1600] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1600\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1600/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1600/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1920] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.6939880952380952).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.6939880952380952).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7778571428571428: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 161.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 256 authors per label:  {'accuracy': [0.7760714285714286, 0.0053737836782297346], 'f1-score': [0.7812431706146038, 0.02142299275496716]}\n",
      "Working with 512 authors per label ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/3f85c0ee804baf604258892a88dd52cdf051d2418a511dcab7cab99a85a3a1b3.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-cased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/795f97c54d814fec7e7c661c939f5f797bd6fb98c93716c51ca7f06335899b9f.27f4ebde81f46ec68cbdd9518932c83dd3d3eac62e312dedfb680d87341e94e9\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20480\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='12800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3200/12800 10:26 < 31:19, 5.11 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.574615</td>\n",
       "      <td>0.695357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.536700</td>\n",
       "      <td>0.576995</td>\n",
       "      <td>0.709167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.578194</td>\n",
       "      <td>0.715238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>0.620873</td>\n",
       "      <td>0.704940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.602264</td>\n",
       "      <td>0.709405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-2560\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-640] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-3200\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-3200/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-3200/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-3200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-3200/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-3200/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-3200/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-960] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1920 (score: 0.7152380952380952).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1920/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1920 (score: 0.7152380952380952).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.81: 100%|███████████████████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 160.18it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20480\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='12800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1920/12800 06:15 < 35:30, 5.11 it/s, Epoch 3/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.589779</td>\n",
       "      <td>0.696845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.604269</td>\n",
       "      <td>0.693214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.627988</td>\n",
       "      <td>0.693155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1280] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Deleting older checkpoint [adapter_checkPoints/gender/checkpoint-1600] due to args.save_total_limit\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-640 (score: 0.6968452380952381).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-640/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-640 (score: 0.6968452380952381).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7792857142857142: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 161.36it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20480\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2560' max='12800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2560/12800 08:18 < 33:14, 5.13 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.603916</td>\n",
       "      <td>0.697143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.573314</td>\n",
       "      <td>0.712262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.594130</td>\n",
       "      <td>0.704821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.633203</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-2560\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7122619047619048).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7122619047619048).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7867857142857143: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 157.80it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20480\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2560' max='12800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2560/12800 08:18 < 33:17, 5.13 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.575700</td>\n",
       "      <td>0.588780</td>\n",
       "      <td>0.702560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521400</td>\n",
       "      <td>0.564126</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486800</td>\n",
       "      <td>0.585550</td>\n",
       "      <td>0.705298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.615798</td>\n",
       "      <td>0.705238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-2560\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7125).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.7125).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7885714285714286: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 159.75it/s]\n",
      "Adding adapter 'gender'.\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train,Val split number 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20480\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12800\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2560' max='12800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2560/12800 08:19 < 33:18, 5.12 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.575700</td>\n",
       "      <td>0.607603</td>\n",
       "      <td>0.690833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521400</td>\n",
       "      <td>0.577315</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486800</td>\n",
       "      <td>0.619093</td>\n",
       "      <td>0.691369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.641859</td>\n",
       "      <td>0.686429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-640\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-640/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-640/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1280\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-1920\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-1920/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-1920/gender/pytorch_model_head.bin\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to adapter_checkPoints/gender/checkpoint-2560\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/adapter_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_adapter.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "Configuration saved in adapter_checkPoints/gender/checkpoint-2560/gender/head_config.json\n",
      "Module weights saved in adapter_checkPoints/gender/checkpoint-2560/gender/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from adapter_checkPoints/gender/checkpoint-1280 (score: 0.6975).\n",
      "Could not locate the best model at adapter_checkPoints/gender/checkpoint-1280/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n",
      "Loading best adapter(s) from adapter_checkPoints/gender/checkpoint-1280 (score: 0.6975).\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/adapter_config.json\n",
      "Overwriting existing adapter 'gender'.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_adapter.bin\n",
      "Loading module configuration from adapter_checkPoints/gender/checkpoint-1280/gender/head_config.json\n",
      "Overwriting existing head 'gender'\n",
      "Adding head 'gender' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from adapter_checkPoints/gender/checkpoint-1280/gender/pytorch_model_head.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 32\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc: 0.7885714285714286: 100%|█████████████████████████████████████████████████████| 2800/2800 [00:17<00:00, 158.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 512 authors per label:  {'accuracy': [0.7906428571428572, 0.010267841614895116], 'f1-score': [0.7873580677573417, 0.016908853577989186]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoAdapterModel\n",
    "from transformers import TrainingArguments, Trainer, AdapterTrainer, EarlyStoppingCallback\n",
    "from TestingPAN17 import compute_accuracy, compute_test_metrics\n",
    "\n",
    "num_v           = len(baseTest.variety_dict)\n",
    "num_labels_dict = {\"gender\": 2, \"variety\": num_v,}\n",
    "\n",
    "FewShot_Results = {}\n",
    "\n",
    "for num in _NUM_AUTHORS_:\n",
    "    # SHOW CURRENT PORTION\n",
    "    print(\"Working with \" + str(num) + \" authors per label ... \")\n",
    "    \n",
    "    dataset_dict = {}\n",
    "    models = {}\n",
    "    \n",
    "    for task_name in tasks:\n",
    "        \n",
    "        # INITIALIZE MODEL-----------------------------------------\n",
    "        \n",
    "        models[task_name] = AutoAdapterModel.from_pretrained(_PRETRAINED_LM_)\n",
    "        \n",
    "        \n",
    "        acc = []\n",
    "        f1s = []\n",
    "        \n",
    "        for val_idx in range(_K_FOLD_CV_):\n",
    "            print(\"Train,Val split number \" + str(val_idx + 1) + \" of \" + str(_K_FOLD_CV_))\n",
    "        \n",
    "            # INITIALIZE ADAPTER-----------------------------------------\n",
    "            \n",
    "            models[task_name].add_adapter(\n",
    "                adapter_name = task_name,\n",
    "                config       = _ADAPTER_CONFIG_\n",
    "            )\n",
    "            \n",
    "            models[task_name].add_classification_head(\n",
    "                head_name    = task_name,\n",
    "                num_labels   = num_labels_dict[task_name],\n",
    "            )\n",
    "            \n",
    "            models[task_name].set_active_adapters(task_name)\n",
    "            models[task_name].train_adapter(task_name)\n",
    "            \n",
    "            # GENERATES DATASET WITH CURRENT PORTION ----------------------\n",
    "            \n",
    "            data_train, data_val = baseTrain.cross_val(k = _K_FOLD_CV_, val_idx = val_idx, num_authors = num)\n",
    "            Train = DatasetCrossVal(Base_Data = data_train, label = 'gender')\n",
    "            Val   = DatasetCrossVal(Base_Data = data_val  , label = 'gender')\n",
    "\n",
    "            # TRAIN ADAPTER--------------------------------------------\n",
    "\n",
    "            training_args = TrainingArguments(\n",
    "                learning_rate               = _LEARNING_RATE_,\n",
    "                num_train_epochs            = _EPOCHS_[task_name],\n",
    "                per_device_train_batch_size = _BATCH_SIZE_,\n",
    "                per_device_eval_batch_size  = _BATCH_SIZE_,\n",
    "                output_dir                  = _OUTPUT_DIR_ + '/' + task_name,\n",
    "                save_total_limit            = 5,\n",
    "                overwrite_output_dir        = True,\n",
    "                remove_unused_columns       = False,\n",
    "                evaluation_strategy         = 'epoch',\n",
    "                logging_strategy            = 'epoch',\n",
    "                save_strategy               = 'epoch',\n",
    "                metric_for_best_model       = 'eval_acc',\n",
    "                load_best_model_at_end      = True,\n",
    "            )\n",
    "\n",
    "            trainer = AdapterTrainer(\n",
    "                model           = models[task_name],\n",
    "                args            = training_args,\n",
    "                train_dataset   = Train,\n",
    "                eval_dataset    = Val,\n",
    "                compute_metrics = compute_accuracy,\n",
    "                callbacks       = [EarlyStoppingCallback(early_stopping_patience = 2, early_stopping_threshold = 0.0001)]\n",
    "            )\n",
    "            trainer.args._n_gpu = _NO_GPUS_\n",
    "\n",
    "            trainer.train()\n",
    "\n",
    "            # TEST MODEL ------------------------------------\n",
    "\n",
    "            results = trainer.predict(Test)\n",
    "            metrics = compute_test_metrics(baseTest, results.predictions, 'gender')\n",
    "            \n",
    "            acc.append(metrics['accuracy'])\n",
    "            f1s.append(metrics['f1-score'])\n",
    "            \n",
    "            # DELETE ADAPTER --------------------------------\n",
    "            \n",
    "            models[task_name].delete_adapter(task_name)\n",
    "            models[task_name].delete_head(task_name)\n",
    "        \n",
    "        acc = np.array(acc)\n",
    "        f1s = np.array(f1s)\n",
    "        \n",
    "        FewShot_Results[num] = {'accuracy': [acc.mean(), acc.std()], 'f1-score': [f1s.mean(), f1s.std()]}\n",
    "        print(\"Results with \" + str(num) + \" authors per label: \", FewShot_Results[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2180ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
